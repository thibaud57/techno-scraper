# Techno-scraper

API pour scraper des donnÃ©es de sites liÃ©s Ã  la musique techno (Soundcloud, Beatport, Bandcamp, Facebook, Instagram, Songstats).

## ğŸ“‹ Description

Techno-scraper est une API FastAPI qui permet de rÃ©cupÃ©rer des donnÃ©es de diffÃ©rents sites liÃ©s Ã  la musique techno. L'API est conÃ§ue pour Ãªtre utilisÃ©e par n8n pour automatiser des workflows de rÃ©cupÃ©ration de donnÃ©es.

## ğŸš€ FonctionnalitÃ©s

### Soundcloud
- **Recherche profils** : Extraction des informations dÃ©taillÃ©es des profils d'artistes
- **Profil par id** : Extraction des donnÃ©es d'un profil en recherchant par son id
- **RÃ©seaux sociaux** : RÃ©cupÃ©ration des liens vers les plateformes externes (Facebook, Instagram, Spotify, etc.)

### Beatport
- **Recherche** : Extraction de donnÃ©es pour les artistes, labels, releases et tracks
- **Releases par artiste/label** : RÃ©cupÃ©ration des sorties musicales d'un artiste ou d'un label avec filtrage par date et pagination

### Ã€ venir
- **Bandcamp** : Informations sur les artistes et leurs albums
- **Facebook/Instagram** : Extraction de donnÃ©es des rÃ©seaux sociaux
- **Songstats** : RÃ©cupÃ©ration des statistiques de streaming

## ğŸ› ï¸ Technologies utilisÃ©es

-   [FastAPI](https://fastapi.tiangolo.com/) - Framework API moderne et performant
-   [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/) - Parsing HTML
-   [HTTPX](https://www.python-httpx.org/) - Client HTTP asynchrone
-   [Pydantic](https://pydantic-docs.helpmanual.io/) - Validation de donnÃ©es
-   [asyncio](https://docs.python.org/3/library/asyncio.html) - Programmation asynchrone pour requÃªtes concurrentes
-   [pytest](https://docs.pytest.org/) - Framework de test
-   [Docker](https://www.docker.com/) - Conteneurisation
-   [GitHub Actions](https://github.com/features/actions) - CI/CD

## ğŸ”§ Installation

### PrÃ©requis

-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/)

### Installation locale

1. Cloner le dÃ©pÃ´t :

    ```bash
    git clone https://github.com/votre-username/techno-scraper.git
    cd techno-scraper
    ```

2. CrÃ©er un fichier `.env` Ã  partir du fichier `.env.example` :

    ```bash
    cp .env.example .env
    ```

3. Modifier le fichier `.env` avec vos propres valeurs.

4. Lancer l'application avec Docker Compose :

    ```bash
    docker-compose up -d
    ```

5. L'API est maintenant accessible Ã  l'adresse [http://localhost:8000](http://localhost:8000)

### Installation sur un VPS

Le projet est configurÃ© pour Ãªtre dÃ©ployÃ© automatiquement sur un VPS via GitHub Actions. Pour configurer le dÃ©ploiement automatique :

1. Forker le dÃ©pÃ´t sur GitHub.

2. Configurer les secrets GitHub suivants :

    - `SSH_HOST` : Adresse IP de votre VPS
    - `SSH_USERNAME` : Nom d'utilisateur SSH
    - `SSH_PRIVATE_KEY` : ClÃ© privÃ©e SSH
    - `SSH_PORT` : Port SSH (gÃ©nÃ©ralement 22)
    - `API_KEY` : ClÃ© API pour l'authentification

3. Pousser vos modifications sur la branche `main` pour dÃ©clencher le dÃ©ploiement automatique.

## ğŸ“š Documentation API

Une fois l'application lancÃ©e, la documentation interactive de l'API est disponible aux adresses suivantes :

-   Swagger UI : [http://localhost:8000/docs](http://localhost:8000/docs)
-   ReDoc : [http://localhost:8000/redoc](http://localhost:8000/redoc)

## ğŸ” Authentification

L'API utilise une authentification par clÃ© API. Pour accÃ©der aux endpoints, vous devez inclure la clÃ© API dans l'en-tÃªte `X-API-Key` de vos requÃªtes.

Exemple :

```bash
curl -X GET "http://localhost:8000/api/soundcloud/profile/123456" -H "X-API-Key: your-api-key-here"
```

## ğŸ§ª Tests

Le projet dispose d'une suite complÃ¨te de tests unitaires et d'intÃ©gration. Pour plus de dÃ©tails, consultez le [README.md des tests](tests/README.md).

Pour exÃ©cuter tous les tests :

```bash
# Sur Windows
.\scripts\run_tests.bat

# Sur Linux/MacOS
./scripts/run_tests.sh

# Avec Docker
docker-compose run --rm techno-scraper pytest
```

Pour exÃ©cuter les tests avec couverture de code :

```bash
pytest --cov=app
```

## ğŸ”„ IntÃ©gration continue

Le projet utilise GitHub Actions pour l'automatisation des tests et du dÃ©ploiement :

- **Workflow test.yml** : ExÃ©cutÃ© automatiquement lors des pull requests
  - ExÃ©cution des tests unitaires et d'intÃ©gration
  - GÃ©nÃ©ration de rapports de couverture de code
  - Peut Ãªtre dÃ©clenchÃ© manuellement via manual-test.yml

- **Workflow build.yml** : Construction de l'image Docker
  - Construction de l'image avec tags appropriÃ©s
  - Publication sur GitHub Container Registry

- **Workflow deploy.yml** : Orchestration du dÃ©ploiement complet
  - DÃ©clenchÃ© par un push sur la branche master
  - Appelle test.yml puis build.yml en sÃ©quence
  - DÃ©ploie sur le VPS via SSH si les Ã©tapes prÃ©cÃ©dentes rÃ©ussissent

Pour plus de dÃ©tails sur les workflows, consultez le dossier `.github/workflows/`.

## ğŸ“ Structure du projet

```
techno-scraper/
â”œâ”€â”€ app/                      # Code source de l'application
â”‚   â”œâ”€â”€ core/                 # FonctionnalitÃ©s centrales
â”‚   â”œâ”€â”€ models/               # ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ routers/              # Endpoints API
â”‚   â”œâ”€â”€ services/             # Services
â”‚   â””â”€â”€ scrapers/             # Modules de scraping
â”œâ”€â”€ tests/                    # Tests unitaires et d'intÃ©gration
â”‚   â”œâ”€â”€ conftest.py           # Configuration des tests
â”‚   â”œâ”€â”€ integration/          # Tests d'intÃ©gration
â”‚   â”œâ”€â”€ mocks/                # Mocks pour les tests
â”‚   â”œâ”€â”€ scrapers/             # Tests des scrapers
â”‚   â””â”€â”€ services/             # Tests des services
â”œâ”€â”€ .github/                  # Configuration GitHub
â”œâ”€â”€ scripts/                  # Scripts utilitaires
â”œâ”€â”€ Dockerfile                # Configuration Docker
â”œâ”€â”€ docker-compose.yml        # Configuration Docker Compose
â””â”€â”€ requirements.txt          # DÃ©pendances Python
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.